tef10_score <- score_questionnaire(
json_string = participant_data[participant_data$trialType == "questionnaire", "response"],
reverse = c(2, 4, 7),
score_min = 0L,
score_max = 4L
)
#### Behavioral summary -------------------------------------------------
## Filter and summarize behavioral data (250–900 ms)
behavior <- summarize_behavior(participant_data, rt_min = 250, rt_max = 900)
#### Save participant summary -------------------------------------------
dir.create("../data/cleaned/participants", recursive = TRUE, showWarnings = FALSE)
## Combine into a single-row participant summary
df_clean <- data.frame(
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
## Save summary CSV to cleaned/participants
write.csv(
df_clean,
file = file.path("../data/cleaned/participants", paste0(subject_id, ".csv")),
row.names = FALSE
)
#### Return output ------------------------------------------------------
stopifnot(nrow(df_clean) == 1)  # one row per participant
return(df_clean)
}
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
process_participant <- function(file_path) {
## Derive a subject id from the filename (no extension)
subject_id <- sub("\\.csv$", "", basename(file_path))
## Read the raw CSV
participant_data <- read.csv(file_path, stringsAsFactors = FALSE)
#### Questionnaire score ------------------------------------------------
## Score questionnaire with our defaults (reverse 2,4,7 on 0–4 scale)
tef10_score <- score_questionnaire(
json_string = participant_data[participant_data$trialType == "questionnaire", "response"],
reverse = c(2, 4, 7),
score_min = 0L,
score_max = 4L
)
#### Behavioral summary -------------------------------------------------
## Filter and summarize behavioral data (250–900 ms)
behavior <- summarize_behavior(participant_data, rt_min = 250, rt_max = 900)
#### Save participant summary -------------------------------------------
dir.create("../data/cleaned/participants", recursive = TRUE, showWarnings = FALSE)
## Combine into a single-row participant summary
df_clean <- data.frame(
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
## Save summary CSV to cleaned/participants
write.csv(
df_clean,
file = file.path("../data/cleaned/participants", paste0(subject_id, ".csv")),
row.names = FALSE
)
#### Return output ------------------------------------------------------
stopifnot(nrow(df_clean) == 1)  # one row per participant
return(df_clean)
}
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
score_questionnaire <- function(json_string,
reverse = c(2, 4, 7),
scale_min = 0L,
scale_max = 4) {
# If the JSON string is missing or empty, return a numeric NA
if (is.null(json_string) || is.na(json_string) || !nzchar(json_string)) {
return(NA_real_)
}
## 1) Parse the JSON string into an R object
##    Use jsonlite::fromJSON() to convert the text into a list.
## Example:
library(jsonlite)
responses <- fromJSON(json_string)
## 2) Flatten and convert to numeric
##    Use unlist() to turn the list into a vector and coerce to numeric if needed.
## Example:
responses <- as.numeric(unlist(responses))
# After parsing + flattening to numeric 'responses':
# responses <- as.numeric(unlist(fromJSON(json_string)))
# If reverse is provided, it must reference valid item positions
if (length(reverse) > 0) {
if (any(reverse < 1 | reverse > length(responses))) {
stop("One or more 'reverse' item indices are out of range for this questionnaire response.")
}
}
## 3) Reverse-score the specified items
if (length(reverse) > 0) {
responses[reverse] <- (scale_max + scale_min) - responses[reverse]
}
## 5) Compute the final score
mean_score <- mean(responses, na.rm = TRUE)
return(mean_score)
}
summarize_behavior(participant_data)
summarize_behavior <- function(df, rt_min = 250, rt_max = 900) {
# Ensure all expected column names are there
if (!all(c("block", "rt", "correct") %in% names(df)) ||
!any(c("trial_type", "trialType") %in% names(df))) {
stop("Input data frame is missing required columns.")
}
## Change correct column to logical
df$correct <- as.logical(df$correct)
## Check if rt column is numeric
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
warning("'rt' column was not numeric. Coerced with as.numeric().")
}
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min & practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min & magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min & parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
# Accuracy 0..1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside [0, 1]. Check 'correct' coding."))
}
}
# Mean RTs within [rt_min, rt_max]
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside [", rt_min, ", ", rt_max, "]."))
}
}
return(participant_summary)
}
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
## Clear environment
rm(list = ls())
source("scripts/process_participant.R")
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("httr", "jsonlite", "fs", "stringr", "lubridate")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", )
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
# Prefer a pattern to avoid accidentally pulling other CSVs
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", )
participant_rows <- lapply(file_list, process_participant)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
if (!require(here)) install.packages("here")
library(here)
score_questionnaire <- function(json_string,
reverse = c(2, 4, 7),
scale_min = 0L,
scale_max = 4) {
# If the JSON string is missing or empty, return a numeric NA
if (is.null(json_string) || is.na(json_string) || !nzchar(json_string)) {
return(NA_real_)
}
## 1) Parse the JSON string into an R object
##    Use jsonlite::fromJSON() to convert the text into a list.
## Example:
library(jsonlite)
responses <- fromJSON(json_string)
## 2) Flatten and convert to numeric
##    Use unlist() to turn the list into a vector and coerce to numeric if needed.
## Example:
responses <- as.numeric(unlist(responses))
# After parsing + flattening to numeric 'responses':
# responses <- as.numeric(unlist(fromJSON(json_string)))
# If reverse is provided, it must reference valid item positions
if (length(reverse) > 0) {
if (any(reverse < 1 | reverse > length(responses))) {
stop("One or more 'reverse' item indices are out of range for this questionnaire response.")
}
}
## 3) Reverse-score the specified items
if (length(reverse) > 0) {
responses[reverse] <- (scale_max + scale_min) - responses[reverse]
}
## 5) Compute the final score
mean_score <- mean(responses, na.rm = TRUE)
return(mean_score)
}
summarize_behavior <- function(df, rt_min = 250, rt_max = 900) {
# Ensure all expected column names are there
if (!all(c("block", "rt", "correct") %in% names(df)) ||
!any(c("trial_type", "trialType") %in% names(df))) {
stop("Input data frame is missing required columns.")
}
## Change correct column to logical
df$correct <- as.logical(df$correct)
## Check if rt column is numeric
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
warning("'rt' column was not numeric. Coerced with as.numeric().")
}
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min & practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min & magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min & parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
# Accuracy 0..1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside [0, 1]. Check 'correct' coding."))
}
}
# Mean RTs within [rt_min, rt_max]
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside [", rt_min, ", ", rt_max, "]."))
}
}
return(participant_summary)
}
process_participant <- function(file_name) {
#### Load File and Extract ID ------------------------------------------------
## Derive a subject id from the filename (no extension)
subject_id <- sub("\\.csv$", "", basename(file_path))
## Read the raw CSV
participant_data <- read.csv(
here::here("data", "raw", file_name),
stringsAsFactors = FALSE
)
#### Questionnaire score -----------------------------------------------------
## Score questionnaire with our defaults (reverse 2,4,7 on 0–4 scale)
tef10_score <- score_questionnaire(
json_string = participant_data[participant_data$trialType == "questionnaire", "response"],
reverse = c(2, 4, 7),
scale_min = 0L,
scale_max = 4L
)
#### Behavioral summary ------------------------------------------------------
## Filter and summarize behavioral data (250–900 ms)
behavior <- summarize_behavior(participant_data, rt_min = 250, rt_max = 900)
#### Save participant summary ------------------------------------------------
## Ensure output directory is created
dir.create(
here::here("data", "cleaned", "participants"),
recursive = TRUE,
showWarnings = FALSE
)
## Combine into a single-row participant summary
df_clean <- data.frame(
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
## Save summary CSV to cleaned/participants
write.csv(
df_clean,
here::here("data", "cleaned", paste0(subject_id, "_processed.csv")),
row.names = FALSE
)
#### Return output -----------------------------------------------------------
stopifnot(nrow(df_clean) == 1)  # one row per participant
return(df_clean)
}
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", )
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
# Prefer a pattern to avoid accidentally pulling other CSVs
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", )
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
# Prefer a pattern to avoid accidentally pulling other CSVs
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", )
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
# Prefer a pattern to avoid accidentally pulling other CSVs
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
study_level <- do.call(rbind, participant_rows)
dir.create("../data/cleaned", recursive = TRUE, showWarnings = FALSE)
write.csv(study_level, "../data/cleaned/study_level.csv", row.names = FALSE)
saveRDS(study_level, "../data/cleaned/study_level.rds")
stopifnot(nrow(study_level) == length(file_list))
head(study_level)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <-
# B) Accuracy difference (complete together)
study_level$acc_diff <-
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_acc - study_level$magnitude_acc
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_acc - study_level$magnitude_acc
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
## ^ for all rows, focuses on averaging two columns, combined w c
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
# Class-level means
colMeans(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
na.rm = TRUE)
# Class-level variability (standard deviations)
sapply(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
sd, na.rm = TRUE)
Parity mean RT is `r round(mean(study_level$parity_mean_rt, na.rm = TRUE), 2)` ms, plus or minus `r round(sd(study_level$parity_mean_rt, na.rm = TRUE), 2)` ms.
round(mean(study_level$parity_mean_rt, na.rm = TRUE), 2)
round(sd(study_level$parity_mean_rt, na.rm = TRUE), 2)
# Create a focus grouping variable from tef10_score
focus_cut <- mean(study_level$tef10_score, na.rm = TRUE)
study_level$focus_group <- ifelse(study_level$tef10_score >= focus_cut,
"High Focus", "Low Focus")
# Aggregate reaction times and differences by focus group
rt_by_focus <- aggregate(
study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
rt_by_focus
View(rt_by_focus)
# Aggregate accuracies and differences by focus group
acc_by_focus <- aggregate(
study_level[, c("magnitude_acc",
"parity_acc",
"acc_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
acc_by_focus
View(acc_by_focus)
str(study_level)
# Summaries for key variables
summary(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff",
"magnitude_acc",
"parity_acc",
"acc_diff")])
# Optional exploration: association between overall RT and overall accuracy
cor(study_level$mean_rt_overall, study_level$mean_acc_overall, use = "complete.obs")
# Make an output directory for tables if needed
dir.create(here("output/tables"), recursive = TRUE, showWarnings = FALSE)
# Build a compact one-row table of overall means and SDs
group_summary <- data.frame(
mean_magnitude_rt = mean(study_level$magnitude_mean_rt, na.rm = TRUE),
mean_parity_rt    = mean(study_level$parity_mean_rt,    na.rm = TRUE),
mean_rt_diff      = mean(study_level$rt_diff,                    na.rm = TRUE),
sd_magnitude_rt   = sd(study_level$magnitude_mean_rt,   na.rm = TRUE),
sd_parity_rt      = sd(study_level$parity_mean_rt,      na.rm = TRUE),
sd_rt_diff        = sd(study_level$rt_diff,                      na.rm = TRUE)
)
# Preview and save
group_summary
write.csv(group_summary, here("output/tables/group_summary.csv"), row.names = FALSE)
saveRDS(group_summary, here("output/tables/group_summary.rds"))
# Confirm
file.exists(here("output/tables/group_summary.csv"))
# Check for missing values
anyNA(study_level)
# Check number of participants
nrow(study_level)
